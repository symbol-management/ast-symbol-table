{
 "tokenizers": {
  "lineno": null,
  "symbols_in_volume": [
   "typing.List",
   "typing.Tuple",
   "typing.Union"
  ],
  "type": "module"
 },
 "tokenizers.decoders": {
  "lineno": null,
  "symbols_in_volume": [],
  "type": "module"
 },
 "tokenizers.implementations": {
  "lineno": null,
  "symbols_in_volume": [],
  "type": "module"
 },
 "tokenizers.implementations.base_tokenizer": {
  "lineno": null,
  "symbols_in_volume": [
   "typing.Tuple"
  ],
  "type": "module"
 },
 "tokenizers.implementations.base_tokenizer.BaseTokenizer": {
  "lineno": 9,
  "symbols_in_volume": [],
  "type": "class"
 },
 "tokenizers.implementations.base_tokenizer.BaseTokenizer.__init__": {
  "lineno": 10,
  "symbols_in_volume": [
   "tokenizers.Tokenizer"
  ],
  "type": "function"
 },
 "tokenizers.implementations.base_tokenizer.BaseTokenizer.__repr__": {
  "lineno": 14,
  "symbols_in_volume": [],
  "type": "function"
 },
 "tokenizers.implementations.base_tokenizer.BaseTokenizer.add_special_tokens": {
  "lineno": 153,
  "symbols_in_volume": [
   "tokenizers.AddedToken",
   "typing.List",
   "typing.Union"
  ],
  "type": "function"
 },
 "tokenizers.implementations.base_tokenizer.BaseTokenizer.add_tokens": {
  "lineno": 140,
  "symbols_in_volume": [
   "tokenizers.AddedToken",
   "typing.List",
   "typing.Union"
  ],
  "type": "function"
 },
 "tokenizers.implementations.base_tokenizer.BaseTokenizer.decode": {
  "lineno": 251,
  "symbols_in_volume": [
   "typing.List",
   "typing.Optional"
  ],
  "type": "function"
 },
 "tokenizers.implementations.base_tokenizer.BaseTokenizer.decode_batch": {
  "lineno": 269,
  "symbols_in_volume": [
   "typing.List",
   "typing.Optional"
  ],
  "type": "function"
 },
 "tokenizers.implementations.base_tokenizer.BaseTokenizer.enable_padding": {
  "lineno": 52,
  "symbols_in_volume": [
   "typing.Optional"
  ],
  "type": "function"
 },
 "tokenizers.implementations.base_tokenizer.BaseTokenizer.enable_truncation": {
  "lineno": 108,
  "symbols_in_volume": [
   "typing.Optional"
  ],
  "type": "function"
 },
 "tokenizers.implementations.base_tokenizer.BaseTokenizer.encode": {
  "lineno": 181,
  "symbols_in_volume": [
   "tokenizers.Encoding",
   "tokenizers.InputSequence",
   "typing.Optional"
  ],
  "type": "function"
 },
 "tokenizers.implementations.base_tokenizer.BaseTokenizer.encode_batch": {
  "lineno": 214,
  "symbols_in_volume": [
   "tokenizers.EncodeInput",
   "tokenizers.Encoding",
   "typing.List"
  ],
  "type": "function"
 },
 "tokenizers.implementations.base_tokenizer.BaseTokenizer.get_vocab": {
  "lineno": 28,
  "symbols_in_volume": [
   "typing.Dict"
  ],
  "type": "function"
 },
 "tokenizers.implementations.base_tokenizer.BaseTokenizer.get_vocab_size": {
  "lineno": 40,
  "symbols_in_volume": [],
  "type": "function"
 },
 "tokenizers.implementations.base_tokenizer.BaseTokenizer.id_to_token": {
  "lineno": 301,
  "symbols_in_volume": [
   "typing.Optional"
  ],
  "type": "function"
 },
 "tokenizers.implementations.base_tokenizer.BaseTokenizer.no_padding": {
  "lineno": 94,
  "symbols_in_volume": [],
  "type": "function"
 },
 "tokenizers.implementations.base_tokenizer.BaseTokenizer.no_truncation": {
  "lineno": 126,
  "symbols_in_volume": [],
  "type": "function"
 },
 "tokenizers.implementations.base_tokenizer.BaseTokenizer.normalize": {
  "lineno": 169,
  "symbols_in_volume": [],
  "type": "function"
 },
 "tokenizers.implementations.base_tokenizer.BaseTokenizer.num_special_tokens_to_add": {
  "lineno": 20,
  "symbols_in_volume": [],
  "type": "function"
 },
 "tokenizers.implementations.base_tokenizer.BaseTokenizer.padding": {
  "lineno": 98,
  "symbols_in_volume": [
   "typing.Optional"
  ],
  "type": "function"
 },
 "tokenizers.implementations.base_tokenizer.BaseTokenizer.post_process": {
  "lineno": 346,
  "symbols_in_volume": [
   "tokenizers.Encoding",
   "typing.Optional"
  ],
  "type": "function"
 },
 "tokenizers.implementations.base_tokenizer.BaseTokenizer.save": {
  "lineno": 325,
  "symbols_in_volume": [],
  "type": "function"
 },
 "tokenizers.implementations.base_tokenizer.BaseTokenizer.save_model": {
  "lineno": 313,
  "symbols_in_volume": [
   "typing.Optional"
  ],
  "type": "function"
 },
 "tokenizers.implementations.base_tokenizer.BaseTokenizer.to_str": {
  "lineno": 334,
  "symbols_in_volume": [],
  "type": "function"
 },
 "tokenizers.implementations.base_tokenizer.BaseTokenizer.token_to_id": {
  "lineno": 289,
  "symbols_in_volume": [
   "typing.Optional"
  ],
  "type": "function"
 },
 "tokenizers.implementations.base_tokenizer.BaseTokenizer.truncation": {
  "lineno": 130,
  "symbols_in_volume": [
   "typing.Optional"
  ],
  "type": "function"
 },
 "tokenizers.implementations.bert_wordpiece": {
  "lineno": null,
  "symbols_in_volume": [],
  "type": "module"
 },
 "tokenizers.implementations.bert_wordpiece.BertWordPieceTokenizer": {
  "lineno": 11,
  "symbols_in_volume": [],
  "type": "class"
 },
 "tokenizers.implementations.bert_wordpiece.BertWordPieceTokenizer.__init__": {
  "lineno": 14,
  "symbols_in_volume": [
   "tokenizers.AddedToken",
   "tokenizers.Tokenizer",
   "tokenizers.decoders.WordPiece",
   "tokenizers.models.WordPiece",
   "tokenizers.normalizers.BertNormalizer",
   "tokenizers.pre_tokenizers.BertPreTokenizer",
   "tokenizers.processors.BertProcessing",
   "typing.Optional",
   "typing.Union"
  ],
  "type": "function"
 },
 "tokenizers.implementations.bert_wordpiece.BertWordPieceTokenizer.train": {
  "lineno": 83,
  "symbols_in_volume": [
   "tokenizers.AddedToken",
   "tokenizers.trainers.WordPieceTrainer",
   "typing.List",
   "typing.Union"
  ],
  "type": "function"
 },
 "tokenizers.implementations.byte_level_bpe": {
  "lineno": null,
  "symbols_in_volume": [],
  "type": "module"
 },
 "tokenizers.implementations.byte_level_bpe.ByteLevelBPETokenizer": {
  "lineno": 9,
  "symbols_in_volume": [],
  "type": "class"
 },
 "tokenizers.implementations.byte_level_bpe.ByteLevelBPETokenizer.__init__": {
  "lineno": 15,
  "symbols_in_volume": [
   "tokenizers.Tokenizer",
   "tokenizers.decoders.ByteLevel",
   "tokenizers.models.BPE",
   "tokenizers.normalizers.Lowercase",
   "tokenizers.normalizers.Sequence",
   "tokenizers.normalizers.unicode_normalizer_from_str",
   "tokenizers.pre_tokenizers.ByteLevel",
   "tokenizers.processors.ByteLevel",
   "typing.Optional"
  ],
  "type": "function"
 },
 "tokenizers.implementations.byte_level_bpe.ByteLevelBPETokenizer.train": {
  "lineno": 73,
  "symbols_in_volume": [
   "tokenizers.AddedToken",
   "tokenizers.pre_tokenizers.ByteLevel.alphabet",
   "tokenizers.trainers.BpeTrainer",
   "typing.List",
   "typing.Union"
  ],
  "type": "function"
 },
 "tokenizers.implementations.char_level_bpe": {
  "lineno": null,
  "symbols_in_volume": [],
  "type": "module"
 },
 "tokenizers.implementations.char_level_bpe.CharBPETokenizer": {
  "lineno": 9,
  "symbols_in_volume": [],
  "type": "class"
 },
 "tokenizers.implementations.char_level_bpe.CharBPETokenizer.__init__": {
  "lineno": 25,
  "symbols_in_volume": [
   "typing.Optional",
   "typing.Union"
  ],
  "type": "function"
 },
 "tokenizers.implementations.char_level_bpe.CharBPETokenizer.train": {
  "lineno": 92,
  "symbols_in_volume": [
   "typing.List",
   "typing.Optional",
   "typing.Union"
  ],
  "type": "function"
 },
 "tokenizers.implementations.sentencepiece_bpe": {
  "lineno": null,
  "symbols_in_volume": [],
  "type": "module"
 },
 "tokenizers.implementations.sentencepiece_bpe.SentencePieceBPETokenizer": {
  "lineno": 9,
  "symbols_in_volume": [],
  "type": "class"
 },
 "tokenizers.implementations.sentencepiece_bpe.SentencePieceBPETokenizer.__init__": {
  "lineno": 15,
  "symbols_in_volume": [
   "tokenizers.AddedToken",
   "tokenizers.Tokenizer",
   "tokenizers.decoders.Metaspace",
   "tokenizers.models.BPE",
   "tokenizers.normalizers.NFKC",
   "tokenizers.pre_tokenizers.Metaspace",
   "typing.Optional",
   "typing.Union"
  ],
  "type": "function"
 },
 "tokenizers.implementations.sentencepiece_bpe.SentencePieceBPETokenizer.train": {
  "lineno": 52,
  "symbols_in_volume": [
   "tokenizers.AddedToken",
   "tokenizers.trainers.BpeTrainer",
   "typing.List",
   "typing.Union"
  ],
  "type": "function"
 },
 "tokenizers.models": {
  "lineno": null,
  "symbols_in_volume": [
   "typing.List",
   "typing.Tuple"
  ],
  "type": "module"
 },
 "tokenizers.normalizers": {
  "lineno": null,
  "symbols_in_volume": [],
  "type": "module"
 },
 "tokenizers.normalizers.unicode_normalizer_from_str": {
  "lineno": 17,
  "symbols_in_volume": [],
  "type": "function"
 },
 "tokenizers.pre_tokenizers": {
  "lineno": null,
  "symbols_in_volume": [],
  "type": "module"
 },
 "tokenizers.processors": {
  "lineno": null,
  "symbols_in_volume": [],
  "type": "module"
 },
 "tokenizers.trainers": {
  "lineno": null,
  "symbols_in_volume": [],
  "type": "module"
 }
}